{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "438856f8-bf54-4bb9-83c1-8518382beb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.video\n",
    "import importlib\n",
    "importlib.reload(utils.video)\n",
    "from utils.video import Video, filter_msgs_to_fps\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plot_helpers.colors import get_colors, transform_to_cv2\n",
    "import utils.rosbag\n",
    "importlib.reload(utils.rosbag)\n",
    "from utils.rosbag import create_frenet_converter, get_trackbounds_from_bag, get_detections_from_bag, get_states_from_bag, get_opponents_trajectories, get_markers_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00419176-e799-43ad-a388-2483c755571a",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name=\"/home/moe/ros_eval/videos/mspliner.mp4\"\n",
    "bag=\"/home/moe/data/multi/video.bag\"\n",
    "HEIGHT=1080\n",
    "WIDTH=960\n",
    "FPS=30\n",
    "colors = [transform_to_cv2(c) for c in get_colors()]\n",
    "TRACK_COLOR = (200, 200, 200)\n",
    "OUTSIDE_COLOR = (255, 255 ,255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5317e46d-ba67-4265-bbb7-380f1d673e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting states |████████████████████████████████████████| 7738/7738 [100%] in 0.3s (23433.16/s) \n",
      "Trackbounds |████████████████████████████████████████| 1119/1119 [100%] in 0.0s (866266.69/s) \n",
      "Detections |████████████████████████████████████████| 3087/3087 [100%] in 0.2s (13028.82/s) \n"
     ]
    }
   ],
   "source": [
    "ego_states = get_states_from_bag(bag)\n",
    "ego_states = filter_msgs_to_fps(ego_states, FPS)\n",
    "fc  = create_frenet_converter(bag)\n",
    "boundary_ext, boundary_int = get_trackbounds_from_bag(bag)\n",
    "det = get_detections_from_bag(bag, fc)\n",
    "d = pd.concat(det, ignore_index=True)\n",
    "ego_states = filter_msgs_to_fps(ego_states, FPS)\n",
    "trajectories = get_opponents_trajectories(bag, last_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24d91895-f70b-4c53-a88d-e7e8de9809de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_row(df, target_value):\n",
    "    closest_index = (df[\"time\"] - target_value).abs().idxmin()\n",
    "    return df.loc[closest_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5aa39609-a301-4b72-8077-1eece08d1772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trajectory_frame(frame, df, video, opp_color):\n",
    "    outer = pd.DataFrame()\n",
    "    inner = pd.DataFrame()\n",
    "    outer[\"x\"], outer[\"y\"] = fc.get_cartesian(df[\"s\"], df[\"d\"] + np.sqrt(df[\"var\"]))\n",
    "    inner[\"x\"], inner[\"y\"] = fc.get_cartesian(df[\"s\"], df[\"d\"] - np.sqrt(df[\"var\"]))\n",
    "    x, y = fc.get_cartesian(df[\"s\"], df[\"d\"])\n",
    "    last_frame = video.add_polygons(\n",
    "        frame, [boundary_ext, outer, inner, boundary_int], colors=[TRACK_COLOR, opp_color, TRACK_COLOR, OUTSIDE_COLOR],alphas=[1.0, 0.6, 1.0, 1.0])\n",
    "    last_frame = video.add_line(last_frame, x, y, opp_color)\n",
    "    last_frame = video.add_points(last_frame, old_x, old_y, color=opp_color, alpha=0.6)\n",
    "    return last_frame, video\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "80be2d5b-c3bc-4212-bb58-5407b1795df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ot_frames(frame, ot_traj, video, opp_traj, opp_color, num_frames=40):\n",
    "    x, y = fc.get_cartesian(opp_traj[\"s\"], opp_traj[\"d\"])\n",
    "    n = ot_traj.shape[0]\n",
    "    step_frame = video.add_line(frame.copy(), x, y, opp_color)\n",
    "    for step in range(1, num_frames + 1):\n",
    "        num_rows = step * n // num_frames\n",
    "        subset = ot_traj.iloc[:num_rows]\n",
    "        step_frame = video.add_line(step_frame, subset['x'].to_list(), subset['y'].to_list(), color=colors[0])\n",
    "        video.add_frame(step_frame)\n",
    "    return video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "15ea627f-6ec6-41f4-a76c-5e09f641d8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding Overtake\n",
      "Adding Overtake\n",
      "Adding Overtake\n",
      "Writing video to /home/moe/ros_eval/videos/mpspliner.mp4\n"
     ]
    }
   ],
   "source": [
    "START_TIME=7\n",
    "TRAJ_UPDATE_TIMES = {\n",
    "    20: 17,\n",
    "    23: 21,\n",
    "    25: \"OT\",\n",
    "    29: \"END_OT\",\n",
    "    40: 31,\n",
    "    45: 32,\n",
    "    50: 35,\n",
    "    56: \"OT\",\n",
    "    60: \"END_OT\",\n",
    "    60.1: 39,\n",
    "    65: \"OT\",\n",
    "    67: \"END_OT\"\n",
    "}\n",
    "\n",
    "\n",
    "update_iterator = iter(TRAJ_UPDATE_TIMES.keys())\n",
    "next_update = next(update_iterator)\n",
    "trajectory_index = None\n",
    "\n",
    "first_time = ego_states.loc[0][\"time\"]\n",
    "vid = Video(video_name, WIDTH, HEIGHT, FPS)\n",
    "frame = vid.get_empty_frame()\n",
    "frame = vid.add_polygons(frame, [boundary_ext.copy(), boundary_int.copy()], colors=[TRACK_COLOR, OUTSIDE_COLOR])\n",
    "old_x = []\n",
    "old_y = []\n",
    "ego_traj = None\n",
    "opp_traj = None\n",
    "opp_color = colors[1]\n",
    "opp_index = 0\n",
    "\n",
    "for idx, state in ego_states.iterrows():\n",
    "    t = state[\"time\"] - first_time\n",
    "    if t < START_TIME:\n",
    "        continue\n",
    "\n",
    "    detection = find_closest_row(d, state[\"time\"])\n",
    "    new_frame = frame.copy()\n",
    "\n",
    "    # add ego car and opponent\n",
    "    new_frame = vid.add_point(new_frame, detection[\"x\"], detection[\"y\"], color=opp_color)\n",
    "    new_frame = vid.add_point(new_frame, state[\"position_x\"], state[\"position_y\"], color=colors[0])\n",
    "    \n",
    "    # Check if update is happening\n",
    "    if t > next_update:\n",
    "        trajectory_index = TRAJ_UPDATE_TIMES[next_update]\n",
    "        try:\n",
    "            next_update = next(update_iterator)\n",
    "        except:\n",
    "            # traj_frame, vid = create_trajectory_frame(\n",
    "            #     new_frame, trajectories[trajectory_index][0], vid, opp_color)\n",
    "            # vid.add_frame(traj_frame, flip=True)\n",
    "            break\n",
    "        \n",
    "\n",
    "    if trajectory_index is not None and trajectory_index not in [\"OT\", \"ACTIVE_OT\", \"END_OT\"]:\n",
    "        # Draw Detections and Trajectory\n",
    "        opp_traj = trajectories[trajectory_index][opp_index]\n",
    "        new_frame = vid.add_points(new_frame, old_x, old_y, color=opp_color, alpha=0.6)\n",
    "        traj_frame, vid = create_trajectory_frame(\n",
    "            new_frame, opp_traj, vid, opp_color)\n",
    "        vid.add_frame(traj_frame, flip=True)\n",
    "        old_x.pop(0)\n",
    "        old_y.pop(0)\n",
    "    elif trajectory_index == \"OT\":\n",
    "        # Draw Overtake Trajectory and start overtake\n",
    "        print(\"Adding Overtake\")\n",
    "        trajectory_index = \"ACTIVE_OT\"\n",
    "        ego_traj = get_markers_before(bag, \"/planner/avoidance/markers_sqp\", state[\"time\"]) # somehow deletes video?\n",
    "        ego_traj = ego_traj[:100]\n",
    "        vid = add_ot_frames(new_frame, ego_traj, vid, opp_traj, opp_color)\n",
    "    elif trajectory_index == \"ACTIVE_OT\":\n",
    "        # Active OT only draw Opponent and Ego car\n",
    "        new_frame = video.add_line(new_frame, ego_traj['x'].to_list(), ego_traj['y'].to_list(), color=colors[0])\n",
    "        vid.add_frame(new_frame)\n",
    "    elif trajectory_index == \"END_OT\":\n",
    "        # OT Finish Go back to trail and draw only detections\n",
    "        trajectory_index = None\n",
    "        opp_color=colors[2]\n",
    "        old_x = []\n",
    "        old_y = []\n",
    "        opp_index = 1\n",
    "    elif trajectory_index is None:\n",
    "        # No trajectory yet only draw detections\n",
    "        new_frame = vid.add_points(new_frame, old_x, old_y, color=opp_color, alpha=0.6)\n",
    "        vid.add_frame(new_frame, flip=True)\n",
    "\n",
    "    old_x.append(detection[\"x\"])\n",
    "    old_y.append(detection[\"y\"])\n",
    "\n",
    "vid.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
